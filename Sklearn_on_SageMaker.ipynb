{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop, Train, Optimize and Deploy bring your own Scikit-Learn based Models on Sagemaker\n",
    "* Doc https://sagemaker.readthedocs.io/en/stable/using_sklearn.html\n",
    "* SDK https://sagemaker.readthedocs.io/en/stable/sagemaker.sklearn.html\n",
    "* boto3 https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#client\n",
    "\n",
    "In this notebook we show how to use Amazon SageMaker to develop, train Scikit-Learn based ML model (Random Forest). We are also demosntrating the hosting of (bring your own) Sickit-Learn Model on Sagemaker. This model is trained on Boston house-price data\n",
    "\n",
    "References\n",
    "\n",
    " * Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
    " * Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "**This sample is provided for demonstration purposes, make sure to conduct appropriate testing if derivating this code for your own use-cases!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation of Whirpool train_labor jupyter notebook Sickit-Learn librararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob\n",
    "import traceback, os, re, gzip, pickle, nltk, multiprocessing, sklearn\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from joblib import Parallel, delayed\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import Ridge,RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import aunsight_connections as au_con\n",
    "#from dslib.ioutils import aunsight_connector\n",
    "import transformer_labor as transformer\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from joblib import Parallel, delayed\n",
    "import re, nltk\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation of Whirpool train_parts jupyter notebook Sickit-Learn librararies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: sklearn_hierarchical_classification in /opt/conda/lib/python3.7/site-packages (1.3.2)\n",
      "Requirement already satisfied: scikit-learn>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from sklearn_hierarchical_classification) (0.22.1)\n",
      "Requirement already satisfied: networkx>=2.4 in /opt/conda/lib/python3.7/site-packages (from sklearn_hierarchical_classification) (2.4)\n",
      "Requirement already satisfied: numpy>=1.13.1 in /opt/conda/lib/python3.7/site-packages (from sklearn_hierarchical_classification) (1.21.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from sklearn_hierarchical_classification) (1.4.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.4->sklearn_hierarchical_classification) (4.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.0->sklearn_hierarchical_classification) (0.14.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install sklearn_hierarchical_classification\n",
    "import nltk, gzip, pickle, multiprocessing, traceback, os, gzip, pickle, json, sklearn\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from textblob import TextBlob\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from nltk.corpus import stopwords\n",
    "import transformer_parts\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import Ridge,RidgeClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn_hierarchical_classification.classifier import HierarchicalClassifier\n",
    "from sklearn_hierarchical_classification.constants import ROOT\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "import datetime\n",
    "\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'sickit_learn_demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation of Whirpool Train_parts Sickit-Learn Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "pipeline = Pipeline([\n",
    "        ('transformations', FeatureUnion([\n",
    "            ('desc_pipe', Pipeline([ # This creates a sparse matrix with one column per word\n",
    "                ('corp', transformer.desc_to_corpus('[^A-Za-z 0-9]')),\n",
    "                ('vect', TfidfVectorizer(lowercase=True, stop_words = \"english\", min_df = 10, max_df = .8, ngram_range=(1,5))),\n",
    "            ])),\n",
    "            ('article_pipe', Pipeline([ # This creates a sparse matrix with one column per word\n",
    "                ('corp', transformer.request_to_corpus('[^A-Za-z 0-9]')),\n",
    "                ('vect', TfidfVectorizer(lowercase=True, stop_words = \"english\", min_df = 10, max_df = .8, ngram_range=(1,5))),\n",
    "            ])),\n",
    "            ('mod_pipe', Pipeline([ \n",
    "                ('prep', transformer.prep_mod()), # needed to pass into TfidfVectorizer\n",
    "                ('vect', TfidfVectorizer(lowercase=True, min_df=10, max_df = .8, norm='l2', tokenizer=transformer.tokenize_mods, ngram_range=(1,5)))\n",
    "            ]))\n",
    "        ])),\n",
    "        ('estimator', RidgeClassifier())\n",
    "    ])\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the Boston housing dataset\n",
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "trainX = pd.DataFrame(X_train, columns=data.feature_names)\n",
    "trainX[\"target\"] = y_train\n",
    "\n",
    "testX = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "testX[\"target\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>7.155</td>\n",
       "      <td>92.2</td>\n",
       "      <td>2.7006</td>\n",
       "      <td>3.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>394.12</td>\n",
       "      <td>4.82</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.53501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>6.152</td>\n",
       "      <td>82.6</td>\n",
       "      <td>1.7455</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>88.01</td>\n",
       "      <td>15.02</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03578</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>7.820</td>\n",
       "      <td>64.5</td>\n",
       "      <td>4.6947</td>\n",
       "      <td>5.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>387.31</td>\n",
       "      <td>3.76</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.38735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>5.613</td>\n",
       "      <td>95.6</td>\n",
       "      <td>1.7572</td>\n",
       "      <td>2.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>359.29</td>\n",
       "      <td>27.26</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>6.333</td>\n",
       "      <td>17.2</td>\n",
       "      <td>5.2146</td>\n",
       "      <td>4.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>375.21</td>\n",
       "      <td>7.34</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS     NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.09103   0.0   2.46   0.0  0.4880  7.155  92.2  2.7006  3.0  193.0   \n",
       "1  3.53501   0.0  19.58   1.0  0.8710  6.152  82.6  1.7455  5.0  403.0   \n",
       "2  0.03578  20.0   3.33   0.0  0.4429  7.820  64.5  4.6947  5.0  216.0   \n",
       "3  0.38735   0.0  25.65   0.0  0.5810  5.613  95.6  1.7572  2.0  188.0   \n",
       "4  0.06724   0.0   3.24   0.0  0.4600  6.333  17.2  5.2146  4.0  430.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     17.8  394.12   4.82    37.9  \n",
       "1     14.7   88.01  15.02    15.6  \n",
       "2     14.9  387.31   3.76    45.4  \n",
       "3     19.1  359.29  27.26    15.7  \n",
       "4     16.9  375.21   7.34    22.6  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.to_csv(\"boston_train.csv\")\n",
    "testX.to_csv(\"boston_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-708870595954/sickit_learn_demo/data/boston_train.csv\n"
     ]
    }
   ],
   "source": [
    "# send data to S3. SageMaker will take training data from s3\n",
    "\n",
    "trainpath = sess.upload_data(\n",
    "    path=\"boston_train.csv\", bucket=bucket, key_prefix=\"sickit_learn_demo/data\"\n",
    ")\n",
    "\n",
    "testpath = sess.upload_data(\n",
    "    path=\"boston_test.csv\", bucket=bucket, key_prefix=\"sickit_learn_demo/data\"\n",
    ")\n",
    "print (trainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a *Script Mode* script\n",
    "The below script contains both training and inference functionality and can run both in SageMaker Training hardware or locally (desktop, SageMaker notebook, on prem, etc). Detailed guidance here https://sagemaker.readthedocs.io/en/stable/using_sklearn.html#preparing-the-scikit-learn-training-script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# inference functions ---------------\n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "   \n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    # to simplify the demo we don't use all sklearn RandomForest hyperparameters\n",
    "    parser.add_argument(\"--n-estimators\", type=int, default=10)\n",
    "    parser.add_argument(\"--min-samples-leaf\", type=int, default=3)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"boston_train.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"boston_test.csv\")\n",
    "    parser.add_argument(\n",
    "        \"--features\", type=str\n",
    "    )  # in this script we ask user to explicitly name features\n",
    "    parser.add_argument(\n",
    "        \"--target\", type=str\n",
    "    )  # in this script we ask user to explicitly name the target\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"reading data\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    print(\"building training and testing datasets\")\n",
    "    X_train = train_df[args.features.split()]\n",
    "    X_test = test_df[args.features.split()]\n",
    "    y_train = train_df[args.target]\n",
    "    y_test = test_df[args.target]\n",
    "\n",
    "    # train\n",
    "    \n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=args.n_estimators, min_samples_leaf=args.min_samples_leaf, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # print abs error\n",
    "    print(\"validating model\")\n",
    "    abs_err = np.abs(model.predict(X_test) - y_test)\n",
    "\n",
    "    # print couple perf metrics\n",
    "    for q in [10, 50, 90]:\n",
    "        print(\"AE-at-\" + str(q) + \"th-percentile: \" + str(np.percentile(a=abs_err, q=q)))\n",
    "\n",
    "    # persist model\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    \n",
    "    joblib.dump(model, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching a training job with Sickil-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the Estimator from the SageMaker Python SDK\n",
    "\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    model_dir=\"s3://sagemaker-us-east-2-708870595954/sickit_learn_demo/model\",\n",
    "    entry_point=\"script.py\",\n",
    "    role=get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    base_job_name=\"rf-scikit\",\n",
    "    metric_definitions=[{\"Name\": \"median-AE\", \"Regex\": \"AE-at-50th-percentile: ([0-9.]+).*$\"}],\n",
    "    hyperparameters={\n",
    "        \"n-estimators\": 2,\n",
    "        \"min-samples-leaf\": 3,\n",
    "        \"features\": \"CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT\",\n",
    "        \"target\": \"target\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-08 18:47:48 Starting - Starting the training job...\n",
      "2021-09-08 18:47:49 Starting - Launching requested ML instancesProfilerReport-1631126867: InProgress\n",
      "......\n",
      "2021-09-08 18:49:05 Starting - Preparing the instances for training......\n",
      "2021-09-08 18:50:05 Downloading - Downloading input data...\n",
      "2021-09-08 18:50:47 Training - Training image download completed. Training in progress.\n",
      "2021-09-08 18:50:47 Uploading - Uploading generated training model\u001b[34m2021-09-08 18:50:37,656 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2021-09-08 18:50:37,658 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-08 18:50:37,667 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-09-08 18:50:37,955 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-08 18:50:40,982 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-08 18:50:40,996 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-08 18:50:41,004 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"features\": \"CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT\",\n",
      "        \"n-estimators\": 2,\n",
      "        \"min-samples-leaf\": 3,\n",
      "        \"target\": \"target\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"rf-scikit-2021-09-08-18-47-47-637\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-708870595954/rf-scikit-2021-09-08-18-47-47-637/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"script.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"features\":\"CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT\",\"min-samples-leaf\":3,\"n-estimators\":2,\"target\":\"target\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-708870595954/rf-scikit-2021-09-08-18-47-47-637/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"features\":\"CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT\",\"min-samples-leaf\":3,\"n-estimators\":2,\"target\":\"target\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rf-scikit-2021-09-08-18-47-47-637\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-708870595954/rf-scikit-2021-09-08-18-47-47-637/source/sourcedir.tar.gz\",\"module_name\":\"script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--features\",\"CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT\",\"--min-samples-leaf\",\"3\",\"--n-estimators\",\"2\",\"--target\",\"target\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURES=CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT\u001b[0m\n",
      "\u001b[34mSM_HP_N-ESTIMATORS=2\u001b[0m\n",
      "\u001b[34mSM_HP_MIN-SAMPLES-LEAF=3\u001b[0m\n",
      "\u001b[34mSM_HP_TARGET=target\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python script.py --features CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT --min-samples-leaf 3 --n-estimators 2 --target target\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mreading data\u001b[0m\n",
      "\u001b[34mbuilding training and testing datasets\u001b[0m\n",
      "\u001b[34mvalidating model\u001b[0m\n",
      "\u001b[34mAE-at-10th-percentile: 0.2650000000000013\u001b[0m\n",
      "\u001b[34mAE-at-50th-percentile: 1.7535714285714281\u001b[0m\n",
      "\u001b[34mAE-at-90th-percentile: 5.713690476190476\u001b[0m\n",
      "\u001b[34m2021-09-08 18:50:42,419 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-09-08 18:51:05 Completed - Training job completed\n",
      "Training seconds: 54\n",
      "Billable seconds: 54\n"
     ]
    }
   ],
   "source": [
    "sklearn_estimator.fit({\"train\": trainpath, \"test\": testpath})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Sickit-Learn model to a real-time model hosting endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-708870595954/rf-scikit-2021-09-08-18-36-15-365/source/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "defauk_model='source/sourcedir.tar.gz'\n",
    "model_data ='s3://'+ bucket+'/rf-scikit-2021-09-08-18-47-47-637/'+ default_mode\n",
    "model_data= \"s3://sagemaker-us-east-2-708870595954/rf-scikit-2021-09-08-18-36-15-365/source/sourcedir.tar.gz\"\n",
    "#model_data = f\"s3://{bucket}/{prefix}/training_artifact/output\"\n",
    "\n",
    "model = SKLearnModel(\n",
    "    #model_data='s3://sagemaker-us-east-2-708870595954/rf-scikit-2021-08-31-22-11-01-583/output/model.tar.gz',\n",
    "    model_data=model_data,\n",
    "    role=get_execution_role(),\n",
    "    entry_point=\"script.py\",\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    ")\n",
    "print (model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bucket)\n",
    "path = os.path.join(args.model_dir, \"model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Sagemaker end point and hosting Sickit-Learn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "prefix = 'sickit_learn_demo'\n",
    "s3_capture_upload_path = f\"s3://{bucket}/{prefix}/output/inferencedata\"\n",
    "endpoint_name = 'Sickit-Learn-latest004' \n",
    "print(\"EndpointName={}\".format(endpoint_name))\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "                        enable_capture=True,\n",
    "                        sampling_percentage=100,\n",
    "                        destination_s3_uri=s3_capture_upload_path)\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1,\n",
    "                instance_type='ml.m4.xlarge',\n",
    "                endpoint_name=endpoint_name,\n",
    "                data_capture_config=data_capture_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictor.predict(testX[data.feature_names]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
